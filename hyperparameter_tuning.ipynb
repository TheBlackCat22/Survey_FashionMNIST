{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGfSHioz4a-y"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt6OqayS4a-0",
        "outputId": "00238098-7cba-4564-ca00-8689aa5b5f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data (X, y):  (60000, 768) (60000,)\n",
            "Test Data (X, y):  (10000, 768) (10000,)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.svm import SVC\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 'vit_b_16_features.pt' file can be obtained by running 'feature_extraction.ipynb'\n",
        "feature_path = './Data/Features/vit_b_16_features.pt'\n",
        "data = torch.load(feature_path)\n",
        "for key, value in data.items():\n",
        "    print(f'{key.capitalize()} Data (X, y): ', value[0].shape, value[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gIDR7pt4a-1"
      },
      "source": [
        "# Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DogHqZh84a-2",
        "outputId": "ebc8cb34-08a7-48db-d2a9-97cf7ede5938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data (X, y):  (55000, 768) (55000,)\n",
            "Test Data (X, y):  (10000, 768) (10000,)\n",
            "Val Data (X, y):  (5000, 768) (5000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    data['train'][0], data['train'][1], test_size=5000, stratify=data['train'][1], random_state=10)\n",
        "data['train'] = [X_train, y_train]\n",
        "data['val'] = [X_val, y_val]\n",
        "\n",
        "for key, value in data.items():\n",
        "    print(f'{key.capitalize()} Data (X, y): ', value[0].shape, value[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lAZagce4a-2"
      },
      "source": [
        "# Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSGStzzq4a-2"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29smKh2y4a-2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pca = PCA()\n",
        "scalar = StandardScaler().fit(data['train'][0])\n",
        "pca.fit(scalar.transform(data['train'][0]))\n",
        "explained_variance_ratios = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "data['train'][0] = pca.transform(scalar.transform(data['train'][0]))\n",
        "data['val'][0] = pca.transform(scalar.transform(data['val'][0]))\n",
        "data['test'][0] = pca.transform(scalar.transform(data['test'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD2dQkYm4a-3"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5n-7HtY4a-3"
      },
      "outputs": [],
      "source": [
        "scalar = StandardScaler().fit(*data['train'])\n",
        "\n",
        "data['train'][0] = scalar.transform(data['train'][0])\n",
        "data['val'][0] = scalar.transform(data['val'][0])\n",
        "data['test'][0] = scalar.transform(data['test'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNiYXfXw4a-3"
      },
      "source": [
        "## Anova Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WJDvwSz4a-3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "scores, _ = f_classif(*data['train'])\n",
        "\n",
        "feature_score = list(zip(range(0, data['train'][0].shape[1]), scores))\n",
        "feature_score = sorted(feature_score, key=lambda item: item[1], reverse=True)\n",
        "\n",
        "feature_ordering = [item[0] for item in feature_score]\n",
        "\n",
        "data['train'][0] = data['train'][0][:, feature_ordering]\n",
        "data['val'][0] = data['val'][0][:, feature_ordering]\n",
        "data['test'][0] = data['test'][0][:, feature_ordering]\n",
        "\n",
        "explained_variance_ratios = np.cumsum(\n",
        "    pca.explained_variance_ratio_[feature_ordering])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leo8rbY_4a-4"
      },
      "source": [
        "## Feature Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qki1j79L4a-4"
      },
      "outputs": [],
      "source": [
        "n_component = 278"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDnV2XMQ4a-4"
      },
      "source": [
        "# SVM Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fklA_mPA4a-4"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "# variables to keep track of the best model, score, and settings to save\n",
        "best_model = 0\n",
        "best_score = 0\n",
        "C_best = 0\n",
        "k_best = '0'\n",
        "\n",
        "for C in tqdm([0.1, 1, 10, 25]):\n",
        "\n",
        "    for k in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
        "\n",
        "        if k == 'poly':\n",
        "            for degree in [2, 3 ,4]:\n",
        "                clf = SVC(C = C, kernel = 'poly', degree = degree, probability = True).fit(data['train'][0][:,:n_component], data['train'][1])\n",
        "                val_preds = clf.predict(data['val'][0][:,:n_component])\n",
        "                s = f1_score(data['val'][1], val_preds, average='macro')\n",
        "                print(f'{{C : {C}, kernel : poly, degree : {degree}}} -> f1_socre = {s}')\n",
        "                if s > best_score:\n",
        "                    best_score = s\n",
        "                    best_model = clf\n",
        "                    C_best = C\n",
        "                    k_best = 'poly_d'+str(degree)\n",
        "        else:\n",
        "            clf = SVC(C = C, kernel = k, probability = True).fit(data['train'][0][:,:n_component], data['train'][1])\n",
        "            val_preds = clf.predict(data['val'][0][:,:n_component])\n",
        "            s = f1_score(data['val'][1], val_preds, average='macro')\n",
        "            print(f'{{C : {C}, kernel : {k}}} -> f1_socre = {s}')\n",
        "            if s > best_score:\n",
        "                best_score = s\n",
        "                best_model = clf\n",
        "                C_best = C\n",
        "                k_best = k\n",
        "\n",
        "torch.save(best_model, './Data/Models/HP_SVM_C'+str(C_best)+'_k_'+k_best+'_f1score_'+str(round(best_score,3))+'.pt')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
